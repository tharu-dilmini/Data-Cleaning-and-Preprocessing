# -*- coding: utf-8 -*-
"""DataCleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gLVSSXNjcMb7g49k0VI1MIM6zdIMlCpo

**Task 1.1: Initial Data Inspection**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

"""Load Dataset"""

hotel_booking = pd.read_csv('/content/hotel_bookings.csv')

"""Display basic information about the dataset:
Shape of the dataset
"""

print("Dataset Shape:", hotel_booking.shape)

"""Data types of each column"""

print(hotel_booking.dtypes)

"""First and last 5 rows"""

print("\nFirst 5 rows:")
print(hotel_booking.head(10))

"""Basic Statical Summary"""

display(hotel_booking.describe(include='all'))

"""**Task 1.2: Missing Value Analysis**

Identify all columns with missing values & Calculate the percentage of missing values for each column
"""

print("Missing Values Summary:")
missing_data = hotel_booking.isnull().sum()
missing_percent = (missing_data / len(hotel_booking)) * 100
missing_summary = pd.DataFrame({
    'Missing_Count': missing_data,
    'Missing_Percentage': missing_percent
}).sort_values('Missing_Count', ascending=False)
print(missing_summary[missing_summary['Missing_Count'] > 0])

"""Visualise missing value patterns using a heatmap"""

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
sns.heatmap(hotel_booking.isnull(), cbar=True, yticklabels=False, cmap='viridis')
plt.title('Missing Data Heatmap')
plt.show()

"""Analyze missing value patterns using a heatmap"""

def analyze_missing_patterns(df):
    """
    Analyze patterns of missing data to understand the mechanism
    """
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100

    missing_table = pd.DataFrame({
        'Missing_Count': missing_data,
        'Missing_Percentage': missing_percent
    }).sort_values('Missing_Count', ascending=False)

    print("Missing Data Summary:")
    print(missing_table[missing_table['Missing_Count'] > 0])

    # Check if missing data is correlated
    print("\nMissing Data Correlation:")
    missing_corr = df.isnull().corr()
    print(missing_corr.stack()[missing_corr.abs().stack() > 0.1])

    return missing_table

missing_summary = analyze_missing_patterns(hotel_booking)

"""**Task 1.3: Data Quality Assessment**

Check duplicate records
"""

print(f"\nDuplicate Records: {hotel_booking.duplicated().sum()}")

"""Identify potential outliers in numerical columns

"""

print("\nNumerical Columns Summary:")
numerical_cols = hotel_booking.select_dtypes(include=[np.number]).columns
print(hotel_booking[numerical_cols].describe())

"""Examine categorical variables for inconsistencies

"""

print("\nCategorical Data Analysis:")
categorical_cols = hotel_booking.select_dtypes(include=['object']).columns

for col in categorical_cols:
    print(f"\n{col} - Unique Values ({hotel_booking[col].nunique()}):")
    value_counts = hotel_booking[col].value_counts()
    print(value_counts)

    # Check for potential inconsistencies (case sensitivity, extra spaces)
    unique_values = hotel_booking[col].dropna().unique()
    print(f"  Potential issues: {[val for val in unique_values if ' ' in str(val) or str(val) != str(val).strip()]}")

"""**Task 2.1: Handling Missing Values**

Handling Missing Values
"""

def analyze_missing_patterns(df):
    """
    Analyze patterns of missing data to understand the mechanism
    """
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100

    missing_table = pd.DataFrame({
        'Missing_Count': missing_data,
        'Missing_Percentage': missing_percent
    }).sort_values('Missing_Count', ascending=False)

    print("Missing Data Summary:")
    print(missing_table[missing_table['Missing_Count'] > 0])

    # Check if missing data is correlated
    print("\nMissing Data Correlation:")
    missing_corr = df.isnull().corr()

    return missing_table

missing_summary = analyze_missing_patterns(hotel_booking)

"""**Task 2.2: Duplicate Detection and Removal**

Identify exact duplicates
"""

print(f"Duplicates before: {hotel_booking.duplicated().sum()}")
hotel_booking = hotel_booking.drop_duplicates()
print(f"After: {hotel_booking.duplicated().sum()}")

"""Find near-duplicates"""

def remove_outliers_iqr(df, column):
    Q1 = hotel_booking[column].quantile(0.25)
    Q3 = hotel_booking[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    return hotel_booking[(hotel_booking[column] >= lower) & (hotel_booking[column] <= upper)]

# Apply to adr
hotel_booking = remove_outliers_iqr(hotel_booking, 'adr')

""" Document the number of duplicates removed"""

hotel_booking_cleaned = hotel_booking.drop_duplicates()
print("Duplicates removed:", hotel_booking.shape[0] - hotel_booking_cleaned.shape[0])

"""**Task 2.3: Outlier Detection and Treatment**

Use the IQR method for outlier detection
"""

from scipy import stats

outlier_cols = ['lead_time', 'stays_in_weekend_nights', 'stays_in_week_nights',
                'adults', 'children', 'babies', 'adr']

"""Apply z-score analysis"""

Q1 = hotel_booking_cleaned['adr'].quantile(0.25)
Q3 = hotel_booking_cleaned['adr'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

"""Create boxplots for visualisation"""

plt.figure(figsize=(8, 5))
sns.boxplot(x=hotel_booking['adr'])
plt.title("Boxplot of ADR (Before Cleaning)")
plt.show()

"""**Task 2.4: Data Inconsistency Fixes**

Fix date format inconsistencies
"""

df = hotel_booking[~((hotel_booking['adults'] == 0) & (hotel_booking['children'] == 0) & (hotel_booking['babies'] == 0))]

# Standardize date format (if applicable)
hotel_booking['reservation_status_date'] = pd.to_datetime(hotel_booking['reservation_status_date'])

"""Handle impossible combinations"""

df_cleaned = hotel_booking_cleaned[~((hotel_booking_cleaned['adults'] == 0) & (hotel_booking_cleaned['children'] == 0) & (hotel_booking_cleaned['babies'] == 0))]

"""**Task 3.1: Data Integrity Checks**

Data Integrity Check
"""

# Guests > 0
assert (df['adults'] + df['children'] + df['babies']).min() > 0

# Date range check
print(df['arrival_date_year'].value_counts())

# Reasonable ranges
print(df[['lead_time', 'adr']].describe())

"""**Task 3.3: Final Dataset Preparation**

Final Dataset Preparation
"""

hotel_booking.to_csv('/content/hotel_bookings.csv', index=False)

data_dict = pd.DataFrame({
    'Column Name': hotel_booking.columns,
    'Description': ['Add descriptions here...'] * len(hotel_booking.columns),
    'Data Type': hotel_booking.dtypes.astype(str).values
})
data_dict.to_csv('/content/hotel_bookings.csv', index=False)

# Final cleaned dataset
# Optional: rename or reset index if needed
df_cleaned = df.copy()
df_cleaned.reset_index(drop=True, inplace=True)

# Export to CSV
df_cleaned.to_csv('/content/hotel_bookings_cleaned.csv', index=False)

# For Colab users: Download the file
from google.colab import files
files.download('/content/hotel_bookings_cleaned.csv')